{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1: Environment Setup\n",
        "Install required libraries and set up the device (GPU/CPU).\n",
        "Steps:\n",
        "\n",
        "1.   Install dependencies quietly.\n",
        "2.   Import core modules.\n",
        "3.   Define global constants (e.g., models, supported formats).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V8ESsgnqqY06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install essential libraries\n",
        "!pip -q install --upgrade diffusers transformers accelerate safetensors gradio pandas pillow openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_-tZWo57xC-",
        "outputId": "1e0641da-36de-4614-ae5b-a4beef09f923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m125.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m133.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Global Constants\n",
        "import os, random, time, json\n",
        "from pathlib import Path\n",
        "from typing import Optional, List\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image, StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "TXT2IMG_MODEL = \"stabilityai/sdxl-turbo\"\n",
        "#FALLBACK_MODEL    = \"timbrooks/instruct-pix2pix\"\n",
        "EDIT_MODEL    = \"OpenGVLab/Step1X-Edit\"\n",
        "SUPPORTED = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")\n"
      ],
      "metadata": {
        "id": "CWEfciniqPHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2: Utility Functions\n",
        "Define helper functions for seeding, timestamping, image discovery, and prompt loading.\n",
        "Steps:\n",
        "\n",
        "1. Implement random seed management for reproducibility.\n",
        "2. Create timestamp generator for file naming.\n",
        "3. Discover images recursively in directories.\n",
        "4. Load prompts from CSV/Excel files."
      ],
      "metadata": {
        "id": "2cXzG9JMr1s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: Utility Functions\n",
        "def seed_everything(seed: Optional[int] = None) -> int:\n",
        "  # Ensures reproducible results across runs\n",
        "    if seed is None or seed < 0:\n",
        "        seed = random.randint(0, 2**31 - 1)\n",
        "    random.seed(seed); torch.manual_seed(seed)\n",
        "    return seed\n",
        "\n",
        "def timestamp():\n",
        "  # Creates unique identifiers for output files\n",
        "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "def discover_images(root_dirs: List[str]) -> List[Path]:\n",
        "  # Recursively finds all supported image files\n",
        "    imgs = []\n",
        "    for root in root_dirs:\n",
        "        p = Path(root)\n",
        "        if not p.exists(): continue\n",
        "        for fp in p.rglob(\"*\"):\n",
        "            if fp.suffix.lower() in SUPPORTED:\n",
        "                imgs.append(fp)\n",
        "    return sorted(imgs)\n",
        "\n",
        "def load_prompts_table(path: Optional[str]) -> pd.DataFrame:\n",
        "  # Loads prompts from CSV/Excel files\n",
        "    if not path: return pd.DataFrame(columns=[\"image\",\"prompt\"])\n",
        "    ext = Path(path).suffix.lower()\n",
        "    if ext in [\".xlsx\",\".xls\"]: return pd.read_excel(path)\n",
        "    if ext == \".csv\": return pd.read_csv(path)\n",
        "    raise ValueError(\"Unsupported prompts file (use .csv or .xlsx)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2ezxJMC97x2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3: Model Initialization\n",
        "Load diffusion pipelines lazily (on first use).\n",
        "Steps:\n",
        "\n",
        "1. Build Text-to-Image pipeline.\n",
        "2. Build Edit pipeline.\n",
        "3. Run inference functions."
      ],
      "metadata": {
        "id": "U7ST_TVDuDJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: Model Initialization\n",
        "def build_txt2img(model_id=TXT2IMG_MODEL):\n",
        "  # Generates high-quality facade images from text prompts\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if DEVICE==\"cuda\" else torch.float32,\n",
        "        variant=\"fp16\" if DEVICE==\"cuda\" else None,\n",
        "        safety_checker=None\n",
        "    )\n",
        "    pipe = pipe.to(DEVICE)\n",
        "    return pipe\n",
        "\n",
        "def build_edit(model_id=EDIT_MODEL, fallback=FALLBACK_MODEL):\n",
        "  # Modifies existing images based on text instructions\n",
        "    pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if DEVICE==\"cuda\" else torch.float32,\n",
        "        safety_checker=None\n",
        "    )\n",
        "    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    pipe = pipe.to(DEVICE)\n",
        "    return pipe\n",
        "\n"
      ],
      "metadata": {
        "id": "xPiUkkDIuCE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Functions"
      ],
      "metadata": {
        "id": "-odCuRe6FNJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "#Text-to-image generation with controllable parameters\n",
        "def run_t2i(pipe, prompt, seed= -1, steps=20, guidance=2.0, width=1024, height=1024):\n",
        "    g = torch.Generator(device=pipe.device).manual_seed(seed_everything(seed))\n",
        "    img = pipe(prompt=prompt, width=width, height=height,\n",
        "               num_inference_steps=steps, guidance_scale=guidance,\n",
        "               generator=g).images[0]\n",
        "    return img\n",
        "\n",
        "@torch.inference_mode()\n",
        "#Instruction-based image editing with guidance controls\n",
        "def run_edit(pipe, init_image: Image.Image, instruction, seed=-1, steps=20, guidance=1.8, image_guidance=1.5):\n",
        "    g = torch.Generator(device=pipe.device).manual_seed(seed_everything(seed))\n",
        "    img = pipe(image=init_image, prompt=instruction,\n",
        "               num_inference_steps=steps, guidance_scale=guidance,\n",
        "               image_guidance_scale=image_guidance,\n",
        "               generator=g).images[0]\n",
        "    return img"
      ],
      "metadata": {
        "id": "3U0ecQEjFFlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 4: Data Preparation Pipeline\n",
        "Purpose: Dataset extraction, organization, and prompt management\n",
        "Dataset Processing\n",
        "\n",
        "1. Extraction: Unzips CMP Facade DB Extended dataset\n",
        "2. Image Discovery: Scans for all supported image formats\n",
        "3. Path Resolution: Maps relative paths to absolute filesystem paths"
      ],
      "metadata": {
        "id": "VrlJZdlLFFPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzips CMP Facade DB Extended dataset\n",
        "import zipfile, os\n",
        "\n",
        "zip_path = \"/content/CMP_facade_DB_extended.zip\"\n",
        "out_dir = \"/content/cmp_facade_extended\"\n",
        "\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(out_dir)\n",
        "\n",
        "print(\"‚úÖ Extracted to:\", out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xse5aky8og1",
        "outputId": "00769fcc-229a-4648-dd1d-5bdafe22778f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: /content/cmp_facade_extended\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, zipfile\n",
        "\n",
        "\n",
        "print(\"ZIPs in /content:\", glob.glob(\"/content/*.zip\"))\n",
        "\n",
        "zip_path = \"/content/CMP_facade_DB_extended.zip\"\n",
        "assert os.path.exists(zip_path), f\"ZIP not found: {zip_path}\"\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    names = z.namelist()\n",
        "    print(\"Total entries in ZIP:\", len(names))\n",
        "    for n in names[:50]:\n",
        "        print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eCMC1ln-vHI",
        "outputId": "f33f1c48-52c6-4d03-8dc4-6211a781aa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZIPs in /content: ['/content/CMP_facade_DB_extended.zip']\n",
            "Total entries in ZIP: 687\n",
            "extended/\n",
            "extended/cmp_x0001.jpg\n",
            "extended/cmp_x0001.png\n",
            "extended/cmp_x0001.xml\n",
            "extended/cmp_x0002.jpg\n",
            "extended/cmp_x0002.png\n",
            "extended/cmp_x0002.xml\n",
            "extended/cmp_x0003.jpg\n",
            "extended/cmp_x0003.png\n",
            "extended/cmp_x0003.xml\n",
            "extended/cmp_x0004.jpg\n",
            "extended/cmp_x0004.png\n",
            "extended/cmp_x0004.xml\n",
            "extended/cmp_x0005.jpg\n",
            "extended/cmp_x0005.png\n",
            "extended/cmp_x0005.xml\n",
            "extended/cmp_x0006.jpg\n",
            "extended/cmp_x0006.png\n",
            "extended/cmp_x0006.xml\n",
            "extended/cmp_x0007.jpg\n",
            "extended/cmp_x0007.png\n",
            "extended/cmp_x0007.xml\n",
            "extended/cmp_x0008.jpg\n",
            "extended/cmp_x0008.png\n",
            "extended/cmp_x0008.xml\n",
            "extended/cmp_x0009.jpg\n",
            "extended/cmp_x0009.png\n",
            "extended/cmp_x0009.xml\n",
            "extended/cmp_x0010.jpg\n",
            "extended/cmp_x0010.png\n",
            "extended/cmp_x0010.xml\n",
            "extended/cmp_x0011.jpg\n",
            "extended/cmp_x0011.png\n",
            "extended/cmp_x0011.xml\n",
            "extended/cmp_x0012.jpg\n",
            "extended/cmp_x0012.png\n",
            "extended/cmp_x0012.xml\n",
            "extended/cmp_x0013.jpg\n",
            "extended/cmp_x0013.png\n",
            "extended/cmp_x0013.xml\n",
            "extended/cmp_x0014.jpg\n",
            "extended/cmp_x0014.png\n",
            "extended/cmp_x0014.xml\n",
            "extended/cmp_x0015.jpg\n",
            "extended/cmp_x0015.png\n",
            "extended/cmp_x0015.xml\n",
            "extended/cmp_x0016.jpg\n",
            "extended/cmp_x0016.png\n",
            "extended/cmp_x0016.xml\n",
            "extended/cmp_x0017.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "\n",
        "zip_path = \"/content/CMP_facade_DB_extended.zip\"\n",
        "out_dir = \"/content/cmp_facade_extended\"\n",
        "oo_dir = \"/content/CMP_facade_DB_base.zip\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(out_dir)\n",
        "print(\"‚úÖ Extracted to:\", out_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEPg5KEQ-54p",
        "outputId": "c0c50d10-8cde-40f3-9e6e-3ffbfd2007f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: /content/cmp_facade_extended\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "IMAGE_EXTS = (\".jpg\",\".jpeg\",\".png\")\n",
        "\n",
        "all_images = []\n",
        "for root, _, files in os.walk(out_dir):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(IMAGE_EXTS):\n",
        "            all_images.append(os.path.join(root, f))\n",
        "\n",
        "print(\"Found images:\", len(all_images))\n",
        "print(\"Examples:\", all_images[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArtqcaFG_k3_",
        "outputId": "e2db6ad6-7228-455c-a34a-8228bd7bef66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found images: 456\n",
            "Examples: ['/content/cmp_facade_extended/extended/cmp_x0002.png', '/content/cmp_facade_extended/extended/cmp_x0178.png', '/content/cmp_facade_extended/extended/cmp_x0103.jpg', '/content/cmp_facade_extended/extended/cmp_x0180.png', '/content/cmp_facade_extended/extended/cmp_x0185.jpg', '/content/cmp_facade_extended/extended/cmp_x0036.jpg', '/content/cmp_facade_extended/extended/cmp_x0014.png', '/content/cmp_facade_extended/extended/cmp_x0124.png', '/content/cmp_facade_extended/extended/cmp_x0216.png', '/content/cmp_facade_extended/extended/cmp_x0068.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discover images\n",
        "DATA_DIRS = [out_dir+\"/extended\"]\n",
        "PROMPTS_FILE = \"/content/facade_prompts_200 (1).xlsx\"\n",
        "OUT_DIR = \"/content/outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "VSN8H6D_AIFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "IMAGE_EXTS = (\".jpg\",\".jpeg\",\".png\")\n",
        "\n",
        "all_images = []\n",
        "for root, _, files in os.walk(out_dir):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(IMAGE_EXTS):\n",
        "            all_images.append(os.path.join(root, f))\n",
        "\n",
        "print(\"Found images:\", len(all_images))\n",
        "print(\"Examples:\", all_images[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhvGjWIqAgBe",
        "outputId": "94a74ea9-fff9-409d-a2d4-0aa1f981fde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found images: 456\n",
            "Examples: ['/content/cmp_facade_extended/extended/cmp_x0002.png', '/content/cmp_facade_extended/extended/cmp_x0178.png', '/content/cmp_facade_extended/extended/cmp_x0103.jpg', '/content/cmp_facade_extended/extended/cmp_x0180.png', '/content/cmp_facade_extended/extended/cmp_x0185.jpg', '/content/cmp_facade_extended/extended/cmp_x0036.jpg', '/content/cmp_facade_extended/extended/cmp_x0014.png', '/content/cmp_facade_extended/extended/cmp_x0124.png', '/content/cmp_facade_extended/extended/cmp_x0216.png', '/content/cmp_facade_extended/extended/cmp_x0068.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.read_excel(\"/content/facade_prompts_200.xlsx\")\n",
        "#Load prompt tables from Excel/CSV files\n",
        "\n",
        "\n",
        "print(df.columns)\n",
        "#Match prompts to corresponding images\n",
        "by_name = {Path(p).name: p for p in all_images}\n",
        "fullpaths = []\n",
        "for name in df['image'].astype(str):\n",
        "    p = by_name.get(name, None)\n",
        "    if p: fullpaths.append(p)\n",
        "    else: fullpaths.append(name)\n",
        "\n",
        "df_fixed = df.copy()\n",
        "df_fixed['image'] = fullpaths\n",
        "\n",
        "csv_fixed = \"/content/facade_prompts_fixed.csv\"\n",
        "df_fixed.to_csv(csv_fixed, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"‚úÖ Wrote fixed CSV:\", csv_fixed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtOFfp7bAOev",
        "outputId": "f857c418-473c-4d06-9a68-9b5220bf0b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image', 'prompt'], dtype='object')\n",
            "‚úÖ Wrote fixed CSV: /content/facade_prompts_fixed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 5: Interactive UI (Gradio)\n",
        "Launch a web UI for real-time generation and editing.\n",
        "Steps:\n",
        "\n",
        "1. Define UI functions.\n",
        "2. Build Gradio blocks with tabs for T2I, Editing, and Dataset Browser."
      ],
      "metadata": {
        "id": "CXGlXJbXtVsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 5: Interactive UI (Gradio)\n",
        "import gradio as gr\n",
        "\n",
        "_t2i_pipe = {\"pipe\": None}\n",
        "_edit_pipe = {\"pipe\": None}\n",
        "DATASET_IMAGES = discover_images(DATA_DIRS) if 'DATA_DIRS' in globals() else []\n",
        "DATASET_CHOICES = [p.name for p in DATASET_IMAGES]\n",
        "\n",
        "def pick_dataset_image(name):\n",
        "    if not name: return None\n",
        "    p = next((p for p in DATASET_IMAGES if p.name==name), None)\n",
        "    if p is None: return None\n",
        "    return Image.open(p).convert(\"RGB\")\n",
        "\n",
        "def ui_t2i(prompt, steps, guidance, width, height, seed):\n",
        "    if _t2i_pipe[\"pipe\"] is None:\n",
        "        _t2i_pipe[\"pipe\"] = build_txt2img()\n",
        "    img = run_t2i(_t2i_pipe[\"pipe\"], prompt, seed, steps, guidance, width, height)\n",
        "    save_path = Path(OUT_DIR)/\"ui_txt2img\"/f\"t2i_{timestamp()}.png\"\n",
        "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img.save(save_path)\n",
        "    return img, str(save_path)\n",
        "\n",
        "def ui_edit(image, instruction, steps, guidance, image_guidance, seed):\n",
        "    if _edit_pipe[\"pipe\"] is None:\n",
        "        _edit_pipe[\"pipe\"] = build_edit()\n",
        "    init = image.convert(\"RGB\")\n",
        "    img = run_edit(_edit_pipe[\"pipe\"], init, instruction, seed, steps, guidance, image_guidance)\n",
        "    save_path = Path(OUT_DIR)/\"ui_edit\"/f\"edit_{timestamp()}.png\"\n",
        "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img.save(save_path)\n",
        "    return img, str(save_path)\n",
        "\n",
        "with gr.Blocks(title=\"StepX1Edit - Facade Studio\") as demo:\n",
        "    gr.Markdown(\"## üß± StepX1Edit ‚Äì Facade Studio (Colab)\\nText‚ÜíImage & Text-Guided Editing\")\n",
        "    with gr.Tab(\"Text ‚Üí Image\"):\n",
        "        prompt = gr.Textbox(label=\"Prompt\", placeholder=\"e.g., modern minimalist glass facade with LED signage\")\n",
        "        with gr.Row():\n",
        "            steps = gr.Slider(4, 40, value=20, step=1, label=\"Steps\")\n",
        "            guidance = gr.Slider(0.5, 7.5, value=2.0, step=0.1, label=\"Guidance\")\n",
        "            width = gr.Slider(512, 1536, value=1024, step=64, label=\"Width\")\n",
        "            height = gr.Slider(512, 1536, value=1024, step=64, label=\"Height\")\n",
        "            seed = gr.Number(value=-1, label=\"Seed (-1=random)\")\n",
        "        btn = gr.Button(\"Generate\")\n",
        "        out_img = gr.Image(label=\"Result\", interactive=False)\n",
        "        out_path = gr.Textbox(label=\"Saved to\", interactive=False)\n",
        "        btn.click(ui_t2i, [prompt, steps, guidance, width, height, seed], [out_img, out_path])\n",
        "\n",
        "    with gr.Tab(\"Edit Existing Image\"):\n",
        "        image = gr.Image(type=\"pil\", label=\"Upload or pick from dataset tab\")\n",
        "        instruction = gr.Textbox(label=\"Instruction\", placeholder=\"e.g., Convert to Islamic mashrabiya style with geometric patterns\")\n",
        "        with gr.Row():\n",
        "            e_steps = gr.Slider(4, 40, value=20, step=1, label=\"Steps\")\n",
        "            e_guid = gr.Slider(0.5, 10.0, value=1.8, step=0.1, label=\"Guidance\")\n",
        "            e_img_guid = gr.Slider(0.5, 5.0, value=1.5, step=0.1, label=\"Image Guidance\")\n",
        "            e_seed = gr.Number(value=-1, label=\"Seed (-1=random)\")\n",
        "        e_btn = gr.Button(\"Edit\")\n",
        "        e_img = gr.Image(label=\"Edited\", interactive=False)\n",
        "        e_path = gr.Textbox(label=\"Saved to\", interactive=False)\n",
        "        e_btn.click(ui_edit, [image, instruction, e_steps, e_guid, e_img_guid, e_seed], [e_img, e_path])\n",
        "\n",
        "    with gr.Tab(\"Dataset Browser\"):\n",
        "        ds_dd = gr.Dropdown(choices=DATASET_CHOICES, label=\"Dataset images (from DATA_DIRS)\")\n",
        "        ds_btn = gr.Button(\"Load to preview\")\n",
        "        ds_img = gr.Image(label=\"Preview\", interactive=False)\n",
        "        ds_btn.click(pick_dataset_image, ds_dd, ds_img)\n",
        "\n",
        "demo.queue().launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "-wH2e9uyASgj",
        "outputId": "ebfe5c68-abe6-4080-e99f-168a4685ea20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e13cc3520c2a29d611.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e13cc3520c2a29d611.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 6: Batch Processing\n",
        "Automated processing of entire datasets with metadata tracking.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Save with metadata.\n",
        "2. Run batch edit or T2I."
      ],
      "metadata": {
        "id": "9xpsxSUDCRul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_with_meta(img, out_path: Path, meta: dict):\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img.save(out_path)\n",
        "    with open(out_path.with_suffix(\".json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def batch_edit(prompts_file: str, data_dirs: List[str], out_dir: str,\n",
        "               steps=20, guidance=1.8, image_guidance=1.5):\n",
        "    df = load_prompts_table(prompts_file).fillna(\"\")\n",
        "    images = discover_images(data_dirs)\n",
        "    lookup = {p.name: p for p in images}\n",
        "    pipe = build_edit()\n",
        "    out_root = Path(out_dir)/f\"edit_{timestamp()}\"\n",
        "    for i, row in df.iterrows():\n",
        "        img_name = str(row.get(\"image\",\"\")).strip()\n",
        "        instr = str(row.get(\"prompt\",\"\")).strip()\n",
        "        if not img_name or not instr: continue\n",
        "        src = lookup.get(Path(img_name).name, None)\n",
        "        if src is None and Path(img_name).exists():\n",
        "            src = Path(img_name)\n",
        "        if src is None:\n",
        "            print(f\"[WARN] Not found: {img_name}\"); continue\n",
        "        init = Image.open(src).convert(\"RGB\")\n",
        "        img = run_edit(pipe, init, instr, seed=-1, steps=steps, guidance=guidance, image_guidance=image_guidance)\n",
        "        out_path = out_root / f\"{src.stem}_edited.png\"\n",
        "        meta = {\"mode\":\"edit\",\"instruction\":instr,\"src\":str(src),\n",
        "                \"steps\":steps,\"guidance\":guidance,\"image_guidance\":image_guidance,\"model\":EDIT_MODEL}\n",
        "        save_with_meta(img, out_path, meta)\n",
        "    print(f\"‚úÖ Done ‚Üí {out_root}\")\n",
        "\n",
        "def batch_t2i(prompts_file: str, out_dir: str, steps=20, guidance=2.0, width=1024, height=1024):\n",
        "    df = load_prompts_table(prompts_file).fillna(\"\")\n",
        "    pipe = build_txt2img()\n",
        "    out_root = Path(out_dir)/f\"t2i_{timestamp()}\"\n",
        "    for i, row in df.iterrows():\n",
        "        prompt = str(row.get(\"prompt\",\"\")).strip()\n",
        "        if not prompt: continue\n",
        "        img = run_t2i(pipe, prompt, seed=-1, steps=steps, guidance=guidance, width=width, height=height)\n",
        "        out_path = out_root / f\"t2i_{i:04d}.png\"\n",
        "        meta = {\"mode\":\"txt2img\",\"prompt\":prompt,\"steps\":steps,\"guidance\":guidance,\"model\":TXT2IMG_MODEL,\"size\":[width,height]}\n",
        "        save_with_meta(img, out_path, meta)\n",
        "    print(f\"‚úÖ Done ‚Üí {out_root}\")\n"
      ],
      "metadata": {
        "id": "FgSIQtwwCqrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBDfpyK0C747"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
